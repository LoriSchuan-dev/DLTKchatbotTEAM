{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt2chatbot_version1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoriSchuan-dev/DLTKchatbotTEAM/blob/main/gpt2chatbot_version1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "outputId": "259f84a1-637b-4a62-c349-014b9ee88a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Nov 15 19:16:12 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5He2U6op5X0Y",
        "outputId": "27d505c5-d397-4c51-a017-4324e15d3aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install gpt-2-simple\n",
        "import gpt_2_simple as gpt2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting gpt-2-simple\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.18.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=0ca9618aff6df1f54594062febada277c0a881570f1cca5ff8d1f813af3a93a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cylvw0jt6zR6",
        "outputId": "a97062b0-3f3b-492e-dcdb-8afb810745d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 429Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 110Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 423Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:08, 158Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 232Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 126Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 174Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3BxNTxpR1ty"
      },
      "source": [
        "There are three released sizes of GPT-2:\n",
        "\n",
        "**124M** (default): the \"small\" model, 500MB on disk.\n",
        "\n",
        "**355M**: the \"medium\" model, 1.5GB on disk.\n",
        "\n",
        "**774M**: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "\n",
        "**1558M**: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H7dSkVzjM3g",
        "outputId": "959e715c-da13-4e38-8365-89b196917303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_F-NK3jSmpN"
      },
      "source": [
        "Mounting Google Drive and get authentication code(copy and paste in the blank)\n",
        "find your dataset file and copy the path link to paste to raw_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWmZ0ryw63ls"
      },
      "source": [
        "raw_data = '/content/drive/My Drive/data.json'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHMSUPTrYzte"
      },
      "source": [
        "if your dataset is a json file, change the link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHyj5LIZqb3e"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(raw_data, 'r') as f:\n",
        "    df =json.load(f)\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6e5Y4C4TXtJ"
      },
      "source": [
        "if your dataset file is a json file, then use it to read the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kE4DQN2TNxQ"
      },
      "source": [
        "data = []\n",
        "\n",
        "for x in df:\n",
        "    for y in range(len(x['dialog'])-1):\n",
        "        a = '[BOT] : ' + x['dialog'][y+1]['text']\n",
        "        q = '[YOU] : ' + x['dialog'][y]['text']\n",
        "        data.append(q)\n",
        "        data.append(a)\n",
        "with open('chatbot.txt', 'w') as f:\n",
        "     for line in data:\n",
        "        try:\n",
        "            f.write(line)\n",
        "            f.write('\\n')\n",
        "        except:\n",
        "            pass\n",
        "file_name = \"/content/chatbot.txt\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNriJV4uTePZ"
      },
      "source": [
        "this data file [] , is only for data.json dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb-eGEoGS1i9"
      },
      "source": [
        "#import os\n",
        "#os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSxQ6k95S6XQ"
      },
      "source": [
        "if you want to kill the previous session, uncomment the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGHxqXIwY4oB"
      },
      "source": [
        "sess = gpt2.start_tf_sess()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuZzjdWt6555",
        "outputId": "c96a7a29-f9cb-4289-e0ff-a7e732d80b7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=500,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=100,\n",
        "              save_every=100\n",
        "              )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:04<00:00,  4.25s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 1015293 tokens\n",
            "Training...\n",
            "[10 | 24.08] loss=1.31 avg=1.31\n",
            "[20 | 39.16] loss=1.00 avg=1.16\n",
            "[30 | 54.44] loss=1.28 avg=1.20\n",
            "[40 | 69.99] loss=1.10 avg=1.18\n",
            "[50 | 85.75] loss=0.97 avg=1.13\n",
            "[60 | 101.78] loss=1.18 avg=1.14\n",
            "[70 | 118.03] loss=1.21 avg=1.15\n",
            "[80 | 134.06] loss=1.03 avg=1.14\n",
            "[90 | 149.99] loss=0.92 avg=1.11\n",
            "[100 | 165.93] loss=0.89 avg=1.09\n",
            "Saving checkpoint/run1/model-100\n",
            "======== SAMPLE 1 ========\n",
            ",  \n",
            "[BOT] : I am a big girl, but like to stay young\n",
            "[YOU] : I am a big girl, but like to stay young\n",
            "[BOT] : I am not sure what that is\n",
            "[YOU] : I am not sure what that is\n",
            "[BOT] : No, I am not sure\n",
            "[YOU] : No, I am not sure\n",
            "[BOT] : I am a big girl but I am not.\n",
            "[YOU] : I am a big girl, but I am not.\n",
            "[BOT] : I am not sure what you are\n",
            "[YOU] : I am not sure what you are\n",
            "[BOT] : No, I am not sure\n",
            "[YOU] : No, I am not sure\n",
            "[BOT] : I am doing well so I am not sure\n",
            "[YOU] : I am doing well so I am not sure\n",
            "[BOT] : I am not sure what that is\n",
            "[YOU] : I am not sure what that is\n",
            "[BOT] : I am not sure what to do with your clothes\n",
            "[YOU] : I am not sure what to do with your clothes\n",
            "[BOT] : Good. I like to think that's what you are doing\n",
            "[YOU] : Good. I like to think that's what you are doing\n",
            "[BOT] : Okay\n",
            "[YOU] : Okay\n",
            "[BOT] : Hello\n",
            "[YOU] : Hello\n",
            "[BOT] : How is it\n",
            "[YOU] : How is it\n",
            "[BOT] : It is well, how is your day?\n",
            "[YOU] : That is okay.\n",
            "[BOT] : What is your favorite color\n",
            "[YOU] : What is your favorite color\n",
            "[BOT] : I like red. I am a huge fan of red, because it is the color of my favorite color\n",
            "[YOU] : I like red. I am a huge fan of red, because it is the color of my favorite color\n",
            "[BOT] : I like red\n",
            "[YOU] : I like red\n",
            "[BOT] : Where did that passion go?\n",
            "[YOU] : Where did that passion go?\n",
            "[BOT] : I am sorry to hear that.\n",
            "[YOU] : I am sorry to hear that.\n",
            "[BOT] : How old are you?\n",
            "[YOU] : How old are you?\n",
            "[BOT] : I am 35\n",
            "[YOU] : I am 35\n",
            "[BOT] : Your mom is a nurse?\n",
            "[YOU] : Your mom is a nurse?\n",
            "[BOT] : Yes. Thank you.\n",
            "[YOU] : Yes. Thank you.\n",
            "[BOT] : I don't have that.\n",
            "[YOU] : I don't have that.\n",
            "[BOT] : Tell me about yourself\n",
            "[YOU] : Tell me about yourself\n",
            "[BOT] : I am a little bit girl.\n",
            "[YOU] : I am a little bit girl.\n",
            "[BOT] : That's okay\n",
            "[YOU] : That's okay\n",
            "[BOT] : What is your name?\n",
            "[YOU] : What is your name?\n",
            "[BOT] : I am named after my favorite color\n",
            "[YOU] : I am named after my favorite color\n",
            "[BOT] : What do you love to do?\n",
            "[YOU] : What do you love to do?\n",
            "[BOT] : Do you like animals?\n",
            "[YOU] : Do you like animals?\n",
            "[BOT] : Yes\n",
            "[YOU] : Yes\n",
            "[BOT] : I have a dog!\n",
            "[YOU] : I have a dog!\n",
            "[BOT] : What about dogs?\n",
            "[YOU] : What about dogs?\n",
            "[BOT] : I have a dog named after my favorite color\n",
            "[YOU] : I have a dog named after my favorite color\n",
            "[BOT] : Do you have any pets\n",
            "[YOU] : Do you have any pets\n",
            "[BOT] : No pets\n",
            "[YOU] : No pet\n",
            "[BOT] : I live with my mum. Do you own a dog?\n",
            "[YOU] : I live with my mum. Do you own a dog?\n",
            "[BOT] : Yeah, do you own a dog\n",
            "[YOU] : Yeah, do you own a dog\n",
            "[BOT] : I own the dog, what do you do for a living?\n",
            "[YOU] : I own the dog, what do you do for a living?\n",
            "[BOT] : I'm a nurse, i love petting dogs\n",
            "[YOU] : I'm a nurse, i love petting dogs\n",
            "[BOT] : No pets\n",
            "[YOU] : No pets\n",
            "[BOT] : I own the dog\n",
            "[YOU] :\n",
            "\n",
            "[110 | 215.58] loss=0.84 avg=1.06\n",
            "[120 | 231.52] loss=1.29 avg=1.08\n",
            "[130 | 247.34] loss=0.90 avg=1.07\n",
            "[140 | 263.25] loss=0.79 avg=1.05\n",
            "[150 | 279.24] loss=0.82 avg=1.03\n",
            "[160 | 295.24] loss=0.63 avg=1.00\n",
            "[170 | 311.19] loss=1.10 avg=1.01\n",
            "[180 | 327.13] loss=0.99 avg=1.01\n",
            "[190 | 343.06] loss=0.90 avg=1.00\n",
            "[200 | 359.01] loss=0.94 avg=1.00\n",
            "Saving checkpoint/run1/model-200\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "======== SAMPLE 1 ========\n",
            " do how is your day going\n",
            "[YOU] : i don t read very much   do you           \n",
            "[BOT] : I don't read very much   do you             \n",
            "[YOU] : i don t read very much   do you             \n",
            "[BOT] : I don't read very much   do you             \n",
            "[YOU] : I don't read very much   do you             \n",
            "[BOT] : I don't read very much   do you            \n",
            "[YOU] : I don't read very much   do you             \n",
            "[BOT] : I don't read very much   do you             \n",
            "[YOU] : I don't read very much   do you               \n",
            "[BOT] : I don't read very much   do you              \n",
            "[YOU] : I don't read very much   do you               \n",
            "[BOT] : I don't read very much   do you               \n",
            "[YOU] : i don t study very much at all   do you                  i m a real estate agent  \n",
            "[BOT] : i don t study very much at all\n",
            "[YOU] : i don t study very much at all\n",
            "[BOT] : i don t study very much at all\n",
            "[YOU] : i don t study very much at all\n",
            "[BOT] : i don t study very much at all\n",
            "[YOU] : i don t study very much at all\n",
            "[BOT] : sorry   but i have not heard of\n",
            "[YOU] : sorry   but i have not heard of\n",
            "[BOT] : sorry   but i am   i am a boy  \n",
            "[YOU] : Sorry for the interruption\n",
            "[BOT] : sorry   i am sorry   do you have a children  \n",
            "[YOU] : sorry   i am sorry   do you have a children  \n",
            "[BOT] : i do not have a son or do you  \n",
            "[YOU] : i do not have a son or do you  \n",
            "[BOT] : sorry   i'm not sorry   i m sorry   do you have a child  \n",
            "[YOU] : sorry   i'm not sorry   i m sorry   do you have a child  \n",
            "[BOT] : i do not have a son\n",
            "[YOU] : i do not have a son\n",
            "[BOT] : sorry         x  have you ever visited  \n",
            "[YOU] : sorry             x  \n",
            "[BOT] : that makes no sense  \n",
            "[YOU] : that makes no sense  \n",
            "[BOT] : sorry            x \n",
            "[YOU] : sorry              x      \n",
            "[BOT] : i don t have a sons so how old are you \n",
            "[YOU] : i don t have a sons so how old are you ?\n",
            "[BOT] : Sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry\n",
            "[YOU] : sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry ok ok\n",
            "[BOT] : sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry\n",
            "[YOU] : sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry sorry Sorry Sorry Sorry Sorry Sorry Sorry Sorry              Sorry sorry    \n",
            "\n",
            "[210 | 403.94] loss=0.92 avg=1.00\n",
            "[220 | 419.88] loss=0.98 avg=0.99\n",
            "[230 | 435.78] loss=0.93 avg=0.99\n",
            "[240 | 451.74] loss=0.84 avg=0.98\n",
            "[250 | 467.76] loss=0.58 avg=0.97\n",
            "[260 | 483.78] loss=0.62 avg=0.95\n",
            "[270 | 499.76] loss=0.95 avg=0.95\n",
            "[280 | 515.72] loss=1.13 avg=0.96\n",
            "[290 | 531.65] loss=0.74 avg=0.95\n",
            "[300 | 547.60] loss=0.97 avg=0.95\n",
            "Saving checkpoint/run1/model-300\n",
            "======== SAMPLE 1 ========\n",
            " i]\n",
            "[BOT] : I'm not a good person. What do you do for a living?\n",
            "[YOU] : I'm not a good person. What do you do for a living?\n",
            "[BOT] : my favorite band is the old school ones😃\n",
            "[YOU] : my favorite band is the old school ones😃\n",
            "[BOT] : I like to look at pictures when I'm not at my computer.\n",
            "[YOU] : I like to look at pictures when I'm not at my computer.\n",
            "[BOT] : how long you have been working?\n",
            "[YOU] : how long you have been working?\n",
            "[BOT] : I am a lawyer. I am a lawyer.\n",
            "[YOU] : I am a lawyer. I am a lawyer.\n",
            "[BOT] : how many lawyers are there in the country?\n",
            "[YOU] : how many lawyers are there in the country?\n",
            "[BOT] : I am a lawyer. I am a lawyer.\n",
            "[YOU] : I am a lawyer. I am a lawyer.\n",
            "[BOT] : you want it to be legal?\n",
            "[YOU] : you want it to be legal?\n",
            "[BOT] : I am a lawyer, but I am not a lawyer right now.\n",
            "[YOU] : I am a lawyer, but I am not a lawyer right now.\n",
            "[BOT] : how old?\n",
            "[YOU] : how old?\n",
            "[BOT] : I'm 24 years old, and i am a doctor.\n",
            "[YOU] : I'm 24 years old, and i am a doctor.\n",
            "[BOT] : what's that name of?\n",
            "[YOU] : what's that name of?\n",
            "[BOT] : I am a doctor.\n",
            "[YOU] : I am a doctor.\n",
            "[BOT] : what kind of person is that?\n",
            "[YOU] : what kind of person is that?\n",
            "[BOT] : I am doctor.\n",
            "[YOU] : I am doctor.\n",
            "[BOT] : what do you do for a living?\n",
            "[YOU] : what do you do for a living?\n",
            "[BOT] : I am a lawyer.\n",
            "[YOU] : I am a lawyer.\n",
            "[BOT] : do you like your job?\n",
            "[YOU] : do you like your job?\n",
            "[BOT] : Yes i do.\n",
            "[YOU] : Yes i do.\n",
            "[BOT] : do you have friends?\n",
            "[YOU] : do you have friends?\n",
            "[BOT] : Yes i do.\n",
            "[YOU] : Yes i do.\n",
            "[BOT] : do you live in a large house?\n",
            "[YOU] : do you live in a large house?\n",
            "[BOT] : In an adult apartment, no, i am still in the army.\n",
            "[YOU] : In an adult apartment, no, i am still in the army.\n",
            "[BOT] : i live in the park , and i live in the park .\n",
            "[YOU] : i live in the park , and i live in the park .\n",
            "[BOT] : I live in the city, but i live in a big house\n",
            "[YOU] : I live in the city, but i live in a big house\n",
            "[BOT] : do you have kids?\n",
            "[YOU] do you have kids?\n",
            "[BOT] : Yes i do, i have a son .\n",
            "[YOU] : Yes i do, i have a son .\n",
            "[BOT] : do you have cats?\n",
            "[YOU] do you have cats?\n",
            "[BOT] : I have a cat named after my favorite color.\n",
            "[YOU] : I have a cat named after my favorite color.\n",
            "[BOT] : do you have a favorite food?\n",
            "[YOU] do you have a favorite food?\n",
            "[BOT] : I like eating at the grocery store.\n",
            "[YOU] : I like eating at the grocery store.\n",
            "[BOT] : do you cook?\n",
            "[YOU] do you cook?\n",
            "[BOT] : I do not cook much, but i like to eat out with my cats .\n",
            "[YOU] : I do not cook much, but i like to eat out with my cats .\n",
            "[BOT] : what makes you cook?\n",
            "[YOU] do you cook?\n",
            "[BOT] : I like to bake and bake bread and pizza , and make pies for friends .\n",
            "[YOU] : I like to bake and bake bread and pizza , and make pies for friends .\n",
            "[BOT] : do you like to cook?\n",
            "[YOU] do you like to cook?\n",
            "[BOT] : I love to bake and bake bread and pizza .\n",
            "[YOU] : I love to bake\n",
            "\n",
            "[310 | 592.56] loss=1.08 avg=0.96\n",
            "[320 | 608.51] loss=1.01 avg=0.96\n",
            "[330 | 624.41] loss=1.00 avg=0.96\n",
            "[340 | 640.34] loss=1.13 avg=0.96\n",
            "[350 | 656.34] loss=0.70 avg=0.96\n",
            "[360 | 672.35] loss=0.90 avg=0.95\n",
            "[370 | 688.36] loss=1.04 avg=0.96\n",
            "[380 | 704.35] loss=0.79 avg=0.95\n",
            "[390 | 720.35] loss=0.88 avg=0.95\n",
            "[400 | 736.31] loss=0.78 avg=0.94\n",
            "Saving checkpoint/run1/model-400\n",
            "======== SAMPLE 1 ========\n",
            "] : I am a little tired.\n",
            "[YOU] : Yo!\n",
            "[BOT] : Hello, how are you? I'm a bit tired.\n",
            "[YOU] : hello ?\n",
            "[BOT] : hi hi Hi, I am a bit of a loner.\n",
            "[YOU] : hi hi hi Hi, I am a bit of a loner.\n",
            "[BOT] : hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi i hav ve hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi ah\n",
            "i really like yo!\n",
            "[YOU] : hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi ho hi ha hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi ho hi hi hi hi hi hi hi hi hi hhaha  \n",
            "[BOT] : hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi i i love hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi so hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi tu hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi ho hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi ho ho hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi lol\n",
            "[YOU] : hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hot hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi Hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi lo hi hi hi lo hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi u do you have any hobbies ?\n",
            "[BOT] : hi hi hi hi hi hi hi hi hi hi hi hi hi hi haa hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi hi haha hi hi hi hi hi ! hi hi hi hi hi hi i'm an audiophile !! i'm looking for the perfect home for my cats !\n",
            "[YOU] : hi hi hi hi hi\n",
            "\n",
            "[410 | 781.18] loss=0.87 avg=0.94\n",
            "[420 | 797.12] loss=1.12 avg=0.95\n",
            "[430 | 813.01] loss=0.71 avg=0.94\n",
            "[440 | 828.96] loss=0.81 avg=0.94\n",
            "[450 | 844.95] loss=0.62 avg=0.93\n",
            "[460 | 860.98] loss=0.81 avg=0.93\n",
            "[470 | 876.94] loss=0.76 avg=0.92\n",
            "[480 | 892.89] loss=0.82 avg=0.92\n",
            "[490 | 908.83] loss=0.95 avg=0.92\n",
            "[500 | 924.75] loss=0.91 avg=0.92\n",
            "Saving checkpoint/run1/model-500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXN91Ui9Toe3"
      },
      "source": [
        "1. change the finetune parameter to meet your goal\n",
        "**length**: Number of tokens to generate (default 1023, the maximum)\n",
        "\n",
        "**temperature**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "\n",
        "**top_k**: Limits the generated guesses to the top k guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set top_k=40)\n",
        "\n",
        "**top_p**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with top_p=0.9)\n",
        "\n",
        "**truncate**: Truncates the input text until a given sequence, excluding that sequence (e.g. if truncate='<|endoftext|>', the returned text will include everything before the first <|endoftext|>). It may be useful to combine this with a smaller length if the input texts are short.\n",
        "\n",
        "**include_prefix**: If using truncate and include_prefix=False, the specified prefix will not be included in the returned text.\n",
        "\n",
        "2. If you're creating an API based on your model and need to pass the generated text elsewhere, you can do text = gpt2.generate(sess, return_as_list=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvXxNGV7T_Ad",
        "outputId": "5106e7b0-9222-452b-92a8-51185de0a2de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='enteryourfilename')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cd0c7a40ab15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_checkpoint_to_gdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'enteryourfilename'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mcopy_checkpoint_to_gdrive\u001b[0;34m(run_name, copy_folder)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m# Reference: https://stackoverflow.com/a/17081026\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/My Drive/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, name, arcname, recursive, exclude, filter)\u001b[0m\n\u001b[1;32m   1936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;31m# Create a TarInfo object from the file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m         \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettarinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mgettarinfo\u001b[0;34m(self, name, arcname, fileobj)\u001b[0m\n\u001b[1;32m   1805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstat\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdereference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                 \u001b[0mstatres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mstatres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoint/enteryourfilename'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me0B1TkaUGvf"
      },
      "source": [
        "copy the trained model to your google drive.\n",
        "remember to change runname in other code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgWblHOuUE42"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='enteryourfilename')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUWa9HetUKQ3"
      },
      "source": [
        "load model from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EgLJmDo7CDZ",
        "outputId": "008a36d8-0d0a-4bb8-9398-378c1ad97b1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "while True:\n",
        "  ques = input(\"[YOU] : \")\n",
        "\n",
        "  inp ='[YOU] : ' +ques+'\\n' +'[BOT]'\n",
        "\n",
        "  x = gpt2.generate(sess,\n",
        "                length=25,\n",
        "                temperature = 0.6,\n",
        "                include_prefix=False,\n",
        "                prefix=inp,\n",
        "                nsamples=1,\n",
        "                )\n",
        "  if ques.strip() == 'bye':\n",
        "      print('[BOT]: nice to talk with you, bye')\n",
        "      break\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[You] : How are you?\n",
            "[YOU] : How are you?\n",
            "[BOT] : I am great! I am doing well. Just got done with a new girlfriend.\n",
            "[YOU] : I am\n",
            "[You] : oh~ you are a fancy guy?\n",
            "[YOU] : oh~ you are a fancy guy?\n",
            "[BOT] : I am not. I am a fairly experienced person.\n",
            "[YOU] : I am not. I am a fairly\n",
            "[You] : what is your profession?\n",
            "[YOU] : what is your profession?\n",
            "[BOT] : I am a chef. I love to cook.\n",
            "[YOU] : I am a chef. I love to cook\n",
            "[You] : bye\n",
            "[YOU] : bye\n",
            "[BOT] : I am a huge fan of the country, but i do not live in the country.\n",
            "[YOU] : I\n",
            "[BOT]: nice to talk with you, bye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb_w1yWHSuGJ",
        "outputId": "e0e0766c-17e1-42ee-830a-a0f2c9e0a2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        }
      },
      "source": [
        "while True:\n",
        "  ques = input(\"Question : \")\n",
        "\n",
        "  inp = '[BOT] :'\n",
        "\n",
        "  x = gpt2.generate(sess,\n",
        "                length=20,\n",
        "                temperature = 0.6,\n",
        "                include_prefix=False,\n",
        "                prefix=inp,\n",
        "                nsamples=1,\n",
        "                return_as_list=True)[0]\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question : how old are you?\n",
            "[YOU] : how old are you?\n",
            "[BOT] : I'm not a good person.\n",
            "[YOU] : I'm not a good person.\n",
            "\n",
            "Question : why you talk nonsense\n",
            "[YOU] : why you talk nonsense\n",
            "[BOT] : I am a student, and I am a student.\n",
            "[YOU] : I am a student\n",
            "Question : why you are a student\n",
            "[YOU] : why you are a student\n",
            "[BOT] : I am a student, but my parents are not very religious\n",
            "[YOU] : I am a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-034bbab8c27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Question : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[YOU] : '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'[BOT] :'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VPDm4y-8AOR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}