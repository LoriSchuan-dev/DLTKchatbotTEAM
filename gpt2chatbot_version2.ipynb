{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt2chatbot_version2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoriSchuan-dev/DLTKchatbotTEAM/blob/main/gpt2chatbot_version2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWcBt-RTsrlF"
      },
      "source": [
        "Dataset: \n",
        "@inproceedings{ min2020ambigqa,\n",
        "    title={ {A}mbig{QA}: Answering Ambiguous Open-domain Questions },\n",
        "    author={ Min, Sewon and Michael, Julian and Hajishirzi, Hannaneh and Zettlemoyer, Luke },\n",
        "    booktitle={ EMNLP },\n",
        "    year={2020}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a96297-c429-4e46-f5c9-a9d1328647b3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Nov 15 23:59:08 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5He2U6op5X0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589e0304-29d8-4c8b-8413-8d43f3f7684b"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install gpt-2-simple\n",
        "import gpt_2_simple as gpt2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting gpt-2-simple\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.18.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=973795d3f544ce4de663d0e965c40444dc57df360020882819aaadc623593444\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cylvw0jt6zR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a27160-2d2c-461a-c9e6-5c659d341258"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 659Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 114Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 448Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:07, 190Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 335Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 109Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 218Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3BxNTxpR1ty"
      },
      "source": [
        "There are three released sizes of GPT-2:\n",
        "\n",
        "**124M** (default): the \"small\" model, 500MB on disk.\n",
        "\n",
        "**355M**: the \"medium\" model, 1.5GB on disk.\n",
        "\n",
        "**774M**: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "\n",
        "**1558M**: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H7dSkVzjM3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ac8f11-bb57-4596-bbf7-f08d6498395e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_F-NK3jSmpN"
      },
      "source": [
        "Mounting Google Drive and get authentication code(copy and paste in the blank)\n",
        "find your dataset file and copy the path link to paste to raw_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cooC-T0JG-V6"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWmZ0ryw63ls"
      },
      "source": [
        "raw_data = '/content/drive/My Drive/train_light.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHMSUPTrYzte"
      },
      "source": [
        "if your dataset is a json file, change the link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHyj5LIZqb3e"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(raw_data, 'r') as f:\n",
        "    df =json.load(f)\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6e5Y4C4TXtJ"
      },
      "source": [
        "if your dataset file is a json file, then use it to read the file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNriJV4uTePZ"
      },
      "source": [
        "this data file [] , is only for data.json dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb-eGEoGS1i9"
      },
      "source": [
        "#import os\n",
        "#os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSxQ6k95S6XQ"
      },
      "source": [
        "if you want to kill the previous session, uncomment the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGHxqXIwY4oB"
      },
      "source": [
        "sess = gpt2.start_tf_sess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E_glPRcjdQk"
      },
      "source": [
        "file_name=\"/content/drive/My Drive/train_light.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuZzjdWt6555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e78207e-4c05-463d-c614-e584408ac9fd"
      },
      "source": [
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=500,\n",
        "              restore_from='latest',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=100,\n",
        "              save_every=100\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint checkpoint/run1/model-500\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:06<00:00,  6.58s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 985641 tokens\n",
            "Training...\n",
            "Saving checkpoint/run1/model-500\n",
            "======== SAMPLE 1 ========\n",
            "Answer\n",
            "[YOU] : i love baking   but i hate cooking  \n",
            "[BOT] : do you like baking\n",
            "[YOU] : do you like baking\n",
            "[BOT] : yes i love it   i am an avid berry person  \n",
            "[YOU] : yes i love it   i am an avid berry person  \n",
            "[BOT] : do you like baking\n",
            "[YOU] : do you like baking\n",
            "[BOT] : no   but if i did, you would probably like baking  \n",
            "[YOU] : no   but if i did, you would probably like baking  \n",
            "[BOT] : did i know that you just said that the answer is: baking\n",
            "[YOU] : did i know that you just said that the answer is: baking\n",
            "[BOT] : yes   do you like baking  \n",
            "[YOU] : yes   do you like baking  \n",
            "[BOT] : what?\n",
            "[YOU] : what?\n",
            "[BOT] : yes   do you like baking  \n",
            "[YOU] : yes   do you like baking  \n",
            "[BOT] : i also know it is my answer\n",
            "[YOU] : i also know it is my answer\n",
            "[BOT] : yes   do you like baking  \n",
            "[YOU] : yes   do you like baking  \n",
            "[BOT] : i am a very experienced baker\n",
            "[YOU] : i am a very experienced baker\n",
            "[BOT] : yes\n",
            "[YOU] : yes\n",
            "[BOT] : yes   do you like baking  \n",
            "[YOU] : yes   do you like baking  \n",
            "[BOT] : i also know that answer is: baking\n",
            "[YOU] : i also know that answer is: baking\n",
            "[BOT] : yes   do you like baking  \n",
            "[YOU] : yes   do you like baking  \n",
            "[BOT] : yeah  \n",
            "[YOU] : yeah  \n",
            "[BOT] : and there is one other answer  \n",
            "[YOU] : and there is one other answer  \n",
            "[BOT] : ok\n",
            "[YOU] : ok\n",
            "[BOT] : do you like it  \n",
            "[YOU] : Hi, how is it? i like riding horses and reading books, you?\n",
            "[BOT] : Hi, how are you? How are you?\n",
            "[YOU] : Hi, how are you? How are you?\n",
            "[BOT] : I am good. Just finished my homework. i want to study law\n",
            "[YOU] : I am good. Just finished my homework. i want to study law\n",
            "[BOT] : I think i will. Do you study literature? I like to study.\n",
            "[YOU] : I think i will. Do you study literature? I like to study.\n",
            "[BOT] : I teach art to but i can not do well in school\n",
            "[YOU] : I teach art to but i can not do well in school\n",
            "[BOT] : I have 3 girls that I am best friends with.\n",
            "[YOU] : I have 3 girls that I am best friends with.\n",
            "[BOT] : I have three girls and 3 boys. Why. 4 boys in one family?\n",
            "[YOU] : I have 3 girls and 3 boys. Why. 4 boys in one family?\n",
            "[BOT] : It is weird\n",
            "[YOU] : It is weird\n",
            "[BOT] : And what do you think?\n",
            "[YOU] : And what do you think?\n",
            "[BOT] : I am a bit of a social person. I do not understand why people are so concerned about the safety of guns.\n",
            "[YOU] : I am a bit of a social person. I do not understand why people are so concerned about the safety of guns.\n",
            "[BOT] : What about people at your job?\n",
            "[YOU] : What about people at your job?\n",
            "[BOT] : I actually like the thought of that. Do you?\n",
            "[YOU] : I actually like the thought of that. Do you?\n",
            "[BOT] : I would like to know what do you think about the police being hired as a solution to gun violence\n",
            "[YOU] : I would like to know what do you think about the police being hired as a solution to gun violence\n",
            "[BOT] : Do you work at the shelter? I work at a shelter\n",
            "[YOU] : Do you work at the shelter? I work at a shelter\n",
            "[BOT] : I work at a shelter\n",
            "[YOU] : I work at a shelter\n",
            "[BOT] : I can't remember which shelter I worked at when I was just a kid\n",
            "[YOU] :\n",
            "\n",
            "[510 | 61.32] loss=1.66 avg=1.66\n",
            "[520 | 77.01] loss=1.68 avg=1.67\n",
            "[530 | 93.00] loss=1.80 avg=1.71\n",
            "[540 | 109.30] loss=1.65 avg=1.70\n",
            "[550 | 125.68] loss=1.79 avg=1.72\n",
            "[560 | 141.90] loss=1.56 avg=1.69\n",
            "[570 | 157.95] loss=1.63 avg=1.68\n",
            "[580 | 174.05] loss=1.46 avg=1.65\n",
            "[590 | 190.21] loss=1.68 avg=1.66\n",
            "[600 | 206.40] loss=1.46 avg=1.64\n",
            "Saving checkpoint/run1/model-600\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "======== SAMPLE 1 ========\n",
            " in a row\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"19 September 2017\"]}], \"id\": \"-53087723571805485548\", \"question\": \"When does the new world order war?\n",
            "[BOT] : Do you like to sleep?\n",
            "[YOU] : Do you like to sleep?\n",
            "[BOT] : I do not know. I am a bit of a student\n",
            "[YOU] : I do not know. I am a bit of a student\n",
            "[BOT] : Do you own a computer program?\n",
            "[YOU] : Do you own a computer program?\n",
            "[BOT] : I did not think so. I am a bit of a student.\n",
            "[YOU] : I did not think so. I am a bit of a student.\n",
            "[BOT] : What kind of music does it carry in the US?\n",
            "[YOU] : What kind of music does it carry in the US?\n",
            "[BOT] : I hear that. What genre can be used in a song in the US?\n",
            "[YOU] : I hear that. What genre can be used in a song in the US?\n",
            "[BOT] : I don't like much rock. I like country music. Why?\n",
            "[YOU] : I don't like much rock. I like country music. Why?\n",
            "[BOT] : It's the kind of music where you find yourself falling out of love with it.\n",
            "[YOU] : It's the kind of music where you find yourself falling out of love with it.\n",
            "[BOT] : The type of music that falls out of love with you. I do not know how often this happens.\n",
            "[YOU] : The type of music that falls out of love with you. I do not know how often this happens.\n",
            "[BOT] : You mean that the guy who plays dave mackinnon's son in the tv series is the son of a famous singer?\n",
            "[YOU] : You mean that the guy who plays dave mackinnon's son in the tv series is the son of a famous singer?\n",
            "[BOT] : I am not much of a singer myself, so I guess you can say that about me.\n",
            "[YOU] : I am not much of a singer myself, so I guess you can say that about me.\n",
            "[BOT] : Okay. Let's see. Who has won the most consecutive premier league domestic cups in the history of the league?\n",
            "[YOU] : Okay. Let's see. Who has won the most consecutive premier league domestic cups in the history of the league?\n",
            "[BOT] : I don't know. Who had won most of the league's domestic cups during their own time?\n",
            "[YOU] : I don't know. Who had won most of the league's domestic cups during their own time?\n",
            "[BOT] : It should be a no-brainer. I love England.\n",
            "[YOU] : It should be a no-brainer. I love England.\n",
            "[BOT] : That's cool. I am from alabama, in the united states of america.\n",
            "[YOU] : That's cool. I am from alabama, in the united states of america.\n",
            "[BOT] : I am in arabia, so i have not had any experience with them. Can i visit your country by plane?\n",
            "[YOU] : I am in arabia, so i have not had any experience with them. Can i visit your country by plane?\n",
            "[BOT] : I'd love to go there though. But I don't have enough time. Are you interested in traveling?\n",
            "[YOU] : I'd love to go there though. But I don't have enough time. Are you interested in traveling?\n",
            "[BOT] : No, i am not. do you have any favorite sport?\n",
            "[YOU] : No, i am not. do you have any favorite sport?\n",
            "[BOT] : Yes, i have a few of them. do you have anything else that you enjoy in your life?\n",
            "[YOU] : Yes, i have a few of them. do you have anything else that you enjoy in your life?\n",
            "[BOT] : I like to listen to music in the fall. i like to listen to music in the fall\n",
            "[YOU] : I like to listen to music in the fall. i like to listen to music in the fall\n",
            "[BOT] : Are you married?\n",
            "[YOU] : Are you married?\n",
            "[BOT] : No, i am not. i am sorry to hear that. i am married to a man\n",
            "[YOU] : No, i am not. i am sorry to hear that. i am married to a man\n",
            "[BOT] : Oh good. So\n",
            "\n",
            "[610 | 252.54] loss=1.67 avg=1.64\n",
            "[620 | 268.76] loss=1.36 avg=1.62\n",
            "[630 | 284.95] loss=1.58 avg=1.61\n",
            "[640 | 301.16] loss=1.49 avg=1.60\n",
            "[650 | 317.35] loss=1.57 avg=1.60\n",
            "[660 | 333.58] loss=1.81 avg=1.61\n",
            "[670 | 349.80] loss=1.64 avg=1.62\n",
            "[680 | 366.03] loss=1.34 avg=1.60\n",
            "[690 | 382.22] loss=1.21 avg=1.58\n",
            "[700 | 398.43] loss=1.42 avg=1.57\n",
            "Saving checkpoint/run1/model-700\n",
            "======== SAMPLE 1 ========\n",
            "551059582708165952,\"question\": \"When was a full moon in greece?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"1948\", \"4\", \"February 25, 1948\"]}], \"id\": \"6243388646977974432\", \"question\": \"When did the nba change the start of their regular season?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"18 March, 1862\", \"1862 march and march to the battle of Gettysburg\"]}], \"id\": \"674769302965181662\", \"question\": \"What year was the war started by who?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"What is the second oldest city in india in terms of population?\", \"answer\": [\"Shahangirao, Chittagong, Jhajpla\"]}, {\"question\": \"What is the third oldest city in india in terms of population?\", \"answer\": [\"Karnataka state, Calcutta\", \"Karnataka, Calcutta\"]}, {\"question\": \"What is the fourth oldest city in india in terms of population?\", \"answer\": [\"Tamil Nadu, Kerala\"]}]}], \"id\": \"402094995580782489\", \"question\": \"Where is the third oldest city in india?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Who won the first round of the gauntlet 2 matches in a row?\", \"answer\": [\"Lil Jon\"]}, {\"question\": \"Who won the last two rounds of the gauntlet 2 matches in a row?\", \"answer\": [\"Jusy\", \"Lil Jusy\"]}, {\"question\": \"Who won the first double elimination match in a row?\", \"answer\": [\"Shawn Michaels\"]}, {\"question\": \"Who won the last two double elimination matches in a row?\", \"answer\": [\"Ric Flair\", \"Shawn Michaels\", \"Ric Flair\"]}]}], \"id\": \"-550168754915687837\", \"question\": \"Who won the first and last double elimination matches in a row?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"In what city did it become officially a crime to play a member of a women's or mixed martial arts organization?\", \"answer\": [\"Austin, Texas\"]}, {\"question\": \"In what city did the ordinance for the establishment of mixed martial arts organizations first became a law, but was actually repealed?\", \"answer\": [\"Phoenix\", \"Phoenix, Arizona\"]}, {\"question\": \"In what city did the amendment to protect mixed martial arts organizations, which was meant to protect them from having to use public places for training, become a law?\", \"answer\": [\"Gulfport, Texas\"]}]}], \"id\": \"-6914287878704437\", \"question\": \"In what city did mixed martial arts organizations become illegal?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Who recorded the song \\\"Good Day Texas\\\" in 1981?\", \"answer\": [\"Loyola, Chicago, Los Angeles, Los Angeles, New York\"]}, {\"question\": \"Who recorded \\\"Good Day Texas\\\" in 1980?\", \"answer\": [\"Dallas, St. Louis, Sacramento, San Antonio, San Francisco\", \"McLeod\\u2019s, Seattle, Atlanta\", \"Lyon\"]}, {\"question\": \"Who recorded \\\"Good Day Texas\\\" after 1987\", \"answer\": [\"Los Angeles\"]}]}], \"id\": \"630525754847704462\", \"question\": \"Who recorded good day texas?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"I am doing well in business as of 11:00 PM on Monday May 8th\", \"answer\": [\"4x4\", \"[3] four-wheel drive vehicle with a 4x4 driver\"]}, {\"question\": \"I am doing well in business as of 11:00 PM on February 27th\", \"answer\": [\"3x3\", \"two-wheel drive vehicle with no passengers\", \"single wheel drive vehicle\"]}, {\"question\": \"I am doing well in business as of 11:00 PM on December 31st\", \"answer\": [\"2x2\", \"two-wheel drive vehicle with no passengers\", \"three-wheel drive vehicle with no passengers\", \"single wheel drive vehicle with no passengers\"]}, {\"question\": \"I am doing well in business as of 11:00 PM on December 16th\", \"answer\": [\"1x1\", \"two-wheel drive vehicle with no passengers\n",
            "\n",
            "[710 | 444.92] loss=1.73 avg=1.58\n",
            "[720 | 461.13] loss=1.48 avg=1.57\n",
            "[730 | 477.31] loss=1.60 avg=1.57\n",
            "[740 | 493.48] loss=1.64 avg=1.58\n",
            "[750 | 509.70] loss=1.31 avg=1.56\n",
            "[760 | 525.88] loss=1.48 avg=1.56\n",
            "[770 | 542.10] loss=1.57 avg=1.56\n",
            "[780 | 558.35] loss=1.24 avg=1.55\n",
            "[790 | 574.56] loss=1.69 avg=1.55\n",
            "[800 | 590.77] loss=1.45 avg=1.55\n",
            "Saving checkpoint/run1/model-800\n",
            "======== SAMPLE 1 ========\n",
            "question\": \"Who is the actor playing the young woman in the movie The Fifth Element?\", \"answer\": [\"Emma Stone\"]}]}], \"id\": \"648812084878385939\", \"question\": \"The five element is my favorite film?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Jody Watley\", \"Karen Jagger\"]}], \"id\": \"623526013089656045\", \"question\": \"Who is the girl that plays skunk in bumblebee?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"John Doe\"]}], \"id\": \"-780858643877995979\", \"question\": \"What was the first bill of rights?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Davy Jones\"]}], \"id\": \"6879132579154848897\", \"question\": \"Who are the two original captains that formed the British side of the fought?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Joseph O'Kelly\"]}], \"id\": \"-660957702701257037\", \"question\": \"Who was the captain that died in the first battle of nauchapel?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"19 December 2015\"]}], \"id\": \"798855140324572708\", \"question\": \"When was the last time houpost gordon was in trouble?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Beth Burdett\"]}], \"id\": \"854140945773466641602\", \"question\": \"Who is the director of america who died in 2015?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Alfred\"]}], \"id\": \"-641518274527095949\", \"question\": \"Who was the voice for the main character in the song?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Which characters are from the 2001 film The Matrix?\", \"answer\": [\"Kyle Connor\", \"Cory Michael Connor\"]}, {\"question\": \"Who played the main character in the film The Matrix?\", \"answer\": [\"Cory Michael Connor\"]}, {\"question\": \"Who plays the main character in the film Matrix 3?\", \"answer\": [\"Cory Michael Connor\"]}, {\"question\": \"Who plays the leading actress in the film Matrix 3?\", \"answer\": [\"Cory Michael Connor\"]}, {\"question\": \"Who plays the principal characters in the film Matrix 3?\", \"answer\": [\"Cory Michael Connor\"]}]}], \"id\": \"-668912120818174837\", \"question\": \"Who are the main characters of the film and the film?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Chinatown, Hong Kong\"]}], \"id\": \"-97908128826390711\", \"question\": \"Where did the movie the man with no hands?\"}]}], \"id\": \"-338975504038124799\", \"question\": \"Where did the movie the man with no hands?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Robert Pattinson\", \"Patrick Anthony Quinn\"]}], \"id\": \"359930643839132639\", \"question\": \"Who won the most oscar for best actor in 2016?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Rafael Benigno Santoro\", \"Rafael Benigno Santoro\"]}], \"id\": \"-490812142822378570\", \"question\": \"Who plays mary librarian in the movies?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Who was the leader of jamaican patriots during the american war of independence?\", \"answer\": [\"John Adams\"]}, {\"question\": \"Who were the leaders of jamaican patriots during the american war of independence?\", \"answer\": [\"William Penn\"]}, {\"question\": \"Who were the leaders of jamaican patriots during the american war of independence as a member of the council of the Union?\", \"answer\": [\"James Monroe\"]}]}], \"id\": \"-310816781311182667\", \"question\": \"Who were the leaders of jamaican patriots during the american war of 1780?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Who has the record for the most\n",
            "\n",
            "[810 | 636.68] loss=1.34 avg=1.54\n",
            "[820 | 652.90] loss=1.41 avg=1.54\n",
            "[830 | 669.06] loss=1.68 avg=1.54\n",
            "[840 | 685.26] loss=1.36 avg=1.54\n",
            "[850 | 701.47] loss=1.27 avg=1.53\n",
            "[860 | 717.72] loss=1.25 avg=1.52\n",
            "[870 | 733.95] loss=1.37 avg=1.51\n",
            "[880 | 750.19] loss=1.42 avg=1.51\n",
            "[890 | 766.42] loss=1.85 avg=1.52\n",
            "[900 | 782.66] loss=1.35 avg=1.51\n",
            "Saving checkpoint/run1/model-900\n",
            "======== SAMPLE 1 ========\n",
            "\": \"true\", \"answer\": [\"Tavares\", \"L.A.'s Tavares\"]}]}], \"id\": \"-7236435284413261413\", \"question\": \"Where is the last movie lion king in the world?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Who is the lead singer of my two dog-themed music videos?\", \"answer\": [\"Bruno Mars\"]}, {\"question\": \"Who is the lead singer of my cat-themed music video?\", \"answer\": [\"Tavares\"]}, {\"question\": \"Who is the lead singer of my cat-themed music video and my daughter's theme song?\", \"answer\": [\"Tavares\"]}]}], \"id\": \"-641316591426750114\", \"question\": \"Who is the lead singer of my cat video?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Ogakora\",\"Mito\",\"Megumi Ogakora\"]}], \"id\": \"-880117481605663414\", \"question\": \"Who was the first official mascot of nyu?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Jawaharlal Nehru\", \"Sir Jawaharlal Nehru\", \"Jawaharlal Nehru\", \"First Prime Minister of India\", \"Jawaharlal Nehru\"]}], \"id\": \"594930854955484796\", \"question\": \"Who was the first prime minister of india?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"The United States\", \"United States\", \"United States and Australia\"]}], \"id\": \"-9295977254534264581\", \"question\": \"Who is the longest serving and influential president in world history?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"When does a game of billiards take place in the United States?\", \"answer\": [\"March 3, 2017\"]}, {\"question\": \"When does billiards take place in the United States on September 29, 2017?\", \"answer\": [\"10:30 a.m. PDT\"]}, {\"question\": \"When does billiards take place in Canada on September 29, 2017?\", \"answer\": [\"Saturday, September 29, 2017\"]}]}], \"id\": \"695966122665696834\", \"question\": \"When does billiards take place in the us?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Who played the young kobe jnner in the 2011 film the city?\", \"answer\": [\"Luke Cage\"]}, {\"question\": \"Who played the old kobe jnner in the 2015 film the city?\", \"answer\": [\"Alycia Debeningham\"]}, {\"question\": \"Who played the woman in the 2014 film the city?\", \"answer\": [\"Charlize Theron\"]}]}], \"id\": \"-486427663907403837\", \"question\": \"Who played the young kobe jnner in the 'the city' film?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Who has played a role in the television show American black soap opera how to be a lady?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"Who is the highest ranked brazilian woman according to FIFA?\", \"answer\": [\"Kasimne M. Sefosha\"]}, {\"question\": \"Who is the highest ranked brazilian woman according to the FIFA world ranking system?\", \"answer\": [\"Chimuena Nica A. Oliveira de Souza\", \"Chimmuena\"]}]}], \"id\": \"567829581627404568\", \"question\": \"Who is the highest ranked woman in brasil?\"}, {\"annotations\": [{\"type\": \"multipleQAs\", \"qaPairs\": [{\"question\": \"What city was the beginning of the word of the year in the US?\", \"answer\": [\"Charlotte\"]}, {\"question\": \"What city was the beginning of the word of the year in the UK?\", \"answer\": [\"Chicago\"]}, {\"question\": \"What city is the beginning of the word of the year in all 50 states?\", \"answer\": [\"Houston\"]}]}], \"id\": \"-6341635377033133345\", \"question\": \"What city is the beginning of the word of the year?\"}, {\"annotations\": [{\"type\": \"singleAnswer\", \"answer\": [\"Puerto Rico\"]}], \"id\n",
            "\n",
            "[910 | 828.43] loss=1.49 avg=1.51\n",
            "[920 | 844.64] loss=1.32 avg=1.51\n",
            "[930 | 860.84] loss=1.48 avg=1.51\n",
            "[940 | 877.02] loss=1.67 avg=1.51\n",
            "[950 | 893.24] loss=1.59 avg=1.51\n",
            "[960 | 909.48] loss=1.52 avg=1.51\n",
            "[970 | 925.69] loss=1.28 avg=1.51\n",
            "[980 | 941.88] loss=1.52 avg=1.51\n",
            "[990 | 958.09] loss=1.54 avg=1.51\n",
            "[1000 | 974.31] loss=1.06 avg=1.50\n",
            "Saving checkpoint/run1/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXN91Ui9Toe3"
      },
      "source": [
        "1. change the finetune parameter to meet your goal\n",
        "**length**: Number of tokens to generate (default 1023, the maximum)\n",
        "\n",
        "**temperature**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "\n",
        "**top_k**: Limits the generated guesses to the top k guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set top_k=40)\n",
        "\n",
        "**top_p**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with top_p=0.9)\n",
        "\n",
        "**truncate**: Truncates the input text until a given sequence, excluding that sequence (e.g. if truncate='<|endoftext|>', the returned text will include everything before the first <|endoftext|>). It may be useful to combine this with a smaller length if the input texts are short.\n",
        "\n",
        "**include_prefix**: If using truncate and include_prefix=False, the specified prefix will not be included in the returned text.\n",
        "\n",
        "2. If you're creating an API based on your model and need to pass the generated text elsewhere, you can do text = gpt2.generate(sess, return_as_list=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvXxNGV7T_Ad"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me0B1TkaUGvf"
      },
      "source": [
        "copy the trained model to your google drive.\n",
        "remember to change runname in other code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EgLJmDo7CDZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a326d74-3e87-4a13-f84b-39d1b7283208"
      },
      "source": [
        "while True:\n",
        "  ques = input(\"[qestion] : \")\n",
        "\n",
        "  inp ='[question] : ' +ques+'\\n' +'[answer]'\n",
        "\n",
        "  x = gpt2.generate(sess,\n",
        "                length=25,\n",
        "                temperature = 0.6,\n",
        "                include_prefix=False,\n",
        "                prefix=inp,\n",
        "                nsamples=1,\n",
        "                )\n",
        "  if ques.strip() == 'bye':\n",
        "      print('[answer]: nice to talk with you, bye')\n",
        "      break\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[qestion] : how are you doing?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) Failed precondition: Attempting to use uninitialized value model/h21/attn/c_proj/w\n\t [[{{node model/h21/attn/c_proj/w/read}}]]\n\t [[strided_slice/_107]]\n  (1) Failed precondition: Attempting to use uninitialized value model/h21/attn/c_proj/w\n\t [[{{node model/h21/attn/c_proj/w/read}}]]\n0 successful operations.\n0 derived errors ignored.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e84dd79802a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0minclude_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mnsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 )\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(sess, run_name, checkpoint_dir, model_name, model_dir, sample_dir, return_as_list, truncate, destination_path, sample_delim, prefix, seed, nsamples, batch_size, length, temperature, top_k, top_p, include_prefix)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             out = sess.run(output, feed_dict={\n\u001b[0;32m--> 471\u001b[0;31m                     \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontext_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m                 })\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) Failed precondition: Attempting to use uninitialized value model/h21/attn/c_proj/w\n\t [[node model/h21/attn/c_proj/w/read (defined at /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[strided_slice/_107]]\n  (1) Failed precondition: Attempting to use uninitialized value model/h21/attn/c_proj/w\n\t [[node model/h21/attn/c_proj/w/read (defined at /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'model/h21/attn/c_proj/w/read':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 462, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 492, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 444, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-e84dd79802a1>\", line 11, in <module>\n    nsamples=1,\n  File \"/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\", line 459, in generate\n    temperature=temperature, top_k=top_k, top_p=top_p\n  File \"/usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py\", line 67, in sample_sequence\n    context_output = step(hparams, context[:, :-1])\n  File \"/usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py\", line 52, in step\n    past=past, reuse=tf.compat.v1.AUTO_REUSE)\n  File \"/usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/model.py\", line 197, in model\n    h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n  File \"/usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/model.py\", line 156, in block\n    a, present = attn(norm(x, 'ln_1'), 'attn', nx, past=past, hparams=hparams)\n  File \"/usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/model.py\", line 141, in attn\n    a = conv1d(a, 'c_proj', n_state)\n  File \"/usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/model.py\", line 83, in conv1d\n    w = tf.compat.v1.get_variable('w', [1, nx, nf], initializer=tf.compat.v1.random_normal_initializer(stddev=w_init_stdev))\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 1500, in get_variable\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 1243, in get_variable\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 567, in get_variable\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 519, in _true_getter\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 933, in _get_single_variable\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 2519, in default_variable_creator\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 1688, in __init__\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 1872, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py\", line 203, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_array_ops.py\", line 4239, in identity\n    \"Identity\", input=input, name=name)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb_w1yWHSuGJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "e0e0766c-17e1-42ee-830a-a0f2c9e0a2ce"
      },
      "source": [
        "while True:\n",
        "  ques = input(\"Question : \")\n",
        "\n",
        "  inp = '[Question] : ' +ques+'\\n' +'[answer]'\n",
        "\n",
        "  x = gpt2.generate(sess,\n",
        "                length=20,\n",
        "                temperature = 0.6,\n",
        "                include_prefix=False,\n",
        "                prefix=inp,\n",
        "                nsamples=1,\n",
        "                return_as_list=True)[0]\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question : how old are you?\n",
            "[YOU] : how old are you?\n",
            "[BOT] : I'm not a good person.\n",
            "[YOU] : I'm not a good person.\n",
            "\n",
            "Question : why you talk nonsense\n",
            "[YOU] : why you talk nonsense\n",
            "[BOT] : I am a student, and I am a student.\n",
            "[YOU] : I am a student\n",
            "Question : why you are a student\n",
            "[YOU] : why you are a student\n",
            "[BOT] : I am a student, but my parents are not very religious\n",
            "[YOU] : I am a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-034bbab8c27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Question : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[YOU] : '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'[BOT] :'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VPDm4y-8AOR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}