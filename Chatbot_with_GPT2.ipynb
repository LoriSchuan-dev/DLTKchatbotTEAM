{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot with GPT2.ipynb",
      "provenance": [],
      "mount_file_id": "1GAs47LulEkhw5Wp_cq_0Rrf2tzBJ5jjw",
      "authorship_tag": "ABX9TyOdvaLiPbc/KPmRBQbcKe8X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoriSchuan-dev/DLTKchatbotTEAM/blob/Dany/Chatbot_with_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "outputId": "653d1419-0fbf-453e-f11a-d26ed14c9ec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 183Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 86.8Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 457Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:06, 228Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 229Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 84.6Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 148Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "outputId": "693c0272-d2f8-4bd4-ef41-a3032686a8f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"robot_text.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)\n",
        "run_name = 'rDany'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name=run_name,\n",
        "              print_every=10,\n",
        "              learning_rate=1e-5,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name=run_name)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name=run_name)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "outputId": "2413e745-52be-4cbf-ab45-d2f8d2de5715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name=run_name)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/rDany/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/rDany/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "outputId": "6acaa0e4-7bec-4a8b-a625-536b43636ec9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#gpt2.generate(sess, run_name='run1')\n",
        "\n",
        "while True:\n",
        "  ques = input(\"[YOU] : \")\n",
        "\n",
        "  inp ='[YOU] : ' +ques+'\\n' +'[BOT]'\n",
        "\n",
        "  if ques.strip() == 'bye':\n",
        "      print('[BOT]: nice to talk with you, bye')\n",
        "      break \n",
        "\n",
        "  x = gpt2.generate(sess,\n",
        "                length=10,\n",
        "                temperature = 0.6,\n",
        "                include_prefix=False,\n",
        "                prefix=inp,\n",
        "                nsamples=1,\n",
        "                run_name=run_name\n",
        "                )\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[YOU] : hi\n",
            "[BOT] : hi there !  ! \n",
            "[AS\n",
            "[YOU] : how are you?\n",
            "[BOT] : いつ、いつも\n",
            "[YOU] : how are you?\n",
            "[BOT] : i'm fine too !  happy to have\n",
            "[YOU] : what is your name?\n",
            "[BOT] :  ན ར\n",
            "[YOU] : what is your name?\n",
            "[BOT] :  ian\n",
            "[YOU] : \n",
            "[YOU] : do you like music?\n",
            "[BOT] : yes ! \n",
            "[YOU] : i\n",
            "[YOU] : do you have eyes?\n",
            "[BOT] : i do. but i'm a robot.\n",
            "[YOU] : nice to meet you\n",
            "[BOT] : hi there !  ! \n",
            "[YOU\n",
            "[YOU] : what do you do?\n",
            "[BOT] : i'm a chatbot 🤖\n",
            "\n",
            "[YOU] : you are a nice chatbot\n",
            "[BOT] : thank you ! \n",
            "[YOU] :\n",
            "[YOU] : what color do you like?\n",
            "[BOT] :     :   \n",
            "\n",
            "[YOU] : do you like sports?\n",
            "[BOT] : yep! and you ?\n",
            "[Y\n",
            "[YOU] : yes, I play tennis and soccer\n",
            "[BOT] : are you human ? \n",
            "[YOU]\n",
            "[YOU] : yes, I am\n",
            "[BOT] :  я? 😄\n",
            "[YOU\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}